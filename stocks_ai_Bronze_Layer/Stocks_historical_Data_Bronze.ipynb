{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2145d7-189d-4eb9-8539-75b8009e7079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# DROP TABLE IF EXISTS stocks_ai.stocks_history_data.stock_history_bronze_layer;\n",
    "# DROP TABLE IF EXISTS stocks_ai.stocks_history_data.stock_history_silver_layer;\n",
    "# DROP SCHEMA IF EXISTS stocks_ai.stocks_history_data;\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94a62f95-dbb5-4037-8b14-ad4a347f2147",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType, IntegerType\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "bronze_table = \"stocks_ai.stocks_history_data.stock_history_bronze_layer\"\n",
    "\n",
    "# Flag: check if table exists for incremental logic\n",
    "if not spark.catalog.tableExists(bronze_table):\n",
    "    is_incremental_flag = 0\n",
    "else:\n",
    "    is_incremental_flag = 1\n",
    "\n",
    "def get_historical_data(tickers, start_date, end_date):\n",
    "    all_records = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "        if not df.empty:\n",
    "            df.reset_index(inplace=True)\n",
    "\n",
    "            # Flatten multiindex: convert ('Open', 'AAPL') to 'open'\n",
    "            df.columns = [col[0].lower() if isinstance(col, tuple) else col.lower() for col in df.columns]\n",
    "\n",
    "            \n",
    "            df['ticker'] = ticker.upper()\n",
    "\n",
    "            all_records.append(df)\n",
    "\n",
    "    if all_records:\n",
    "        combined_df = pd.concat(all_records, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Get ticker list from master table\n",
    "stock_names_df = spark.sql(\"SELECT * FROM stocks_ai.stocks_name_ticker.stock_names\")\n",
    "stock_list = [row['ticker'] for row in stock_names_df.collect()]\n",
    "\n",
    "# Determine start date\n",
    "if is_incremental_flag == 0:\n",
    "    start_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')\n",
    "else:\n",
    "    latest_date = spark.read.table(bronze_table) \\\n",
    "                            .agg(max(\"date\").alias(\"latest_date\")) \\\n",
    "                            .collect()[0][\"latest_date\"]\n",
    "    start_date = (latest_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "historical_df = get_historical_data(stock_list, start_date, end_date)\n",
    "\n",
    "if not historical_df.empty:\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    df_spark = spark.createDataFrame(historical_df)\n",
    "\n",
    "    \n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS stocks_ai.stocks_history_data\")\n",
    "\n",
    "    \n",
    "    write_mode = \"overwrite\" if is_incremental_flag == 0 else \"append\"\n",
    "    df_spark.write.format(\"delta\").mode(write_mode).saveAsTable(bronze_table)\n",
    "else:\n",
    "    print(\"No data to write.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17ee8766-62a0-42cf-96e7-1055e166fd2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cebec221-4206-40ed-9b09-6e0939091344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "MultiIndex([( 'Close', 'AAPL'),\n",
       "            (  'High', 'AAPL'),\n",
       "            (   'Low', 'AAPL'),\n",
       "            (  'Open', 'AAPL'),\n",
       "            ('Volume', 'AAPL')],\n",
       "           names=['Price', 'Ticker'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2371312c-1ff6-4ba7-9dc3-5c2eb3a377a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8031851430104303,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Stocks_historical_Data_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}