{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea6917d-6e44-49c9-b3a3-d4faff3bca39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Silver Layer for Historical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1615f59c-06d3-467d-a4fe-6df50f047d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e1e32a1-0aea-48e0-acce-d132f6fc90bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, round as pyspark_round, col, trim\n",
    "\n",
    "\n",
    "historical_df = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM stocks_ai.stocks_history_data.stock_history_bronze_layer\n",
    "\"\"\")\n",
    "\n",
    "transformed_df = (\n",
    "    historical_df\n",
    "    .withColumn(\"date\", date_format(\"date\", \"MM-dd-yyyy\"))\n",
    "    .withColumn(\"close\", pyspark_round(col(\"close\"), 3))\n",
    "    .withColumn(\"high\", pyspark_round(col(\"high\"), 3))\n",
    "    .withColumn(\"low\", pyspark_round(col(\"low\"), 3))\n",
    "    .withColumn(\"open\", pyspark_round(col(\"open\"), 3))\n",
    "    .withColumn(\"volume\", col(\"volume\"))\n",
    "    .withColumn(\"ticker\", col(\"ticker\"))  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "transformed_df.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"stocks_ai.stocks_history_data.stock_history_silver_layer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d508680-dc4b-4e83-adca-b8b883ee852f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Silver Layer for News_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0be2dbc-92cd-4ccc-a7ee-079f1ab0693f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, col, trim\n",
    "\n",
    "# Load bronze ne\n",
    "news_df = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM stocks_ai.stocks_news_data.stock_news_bronze_layer\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "news_silver_df = (\n",
    "    news_df\n",
    "    .filter(col(\"summary\").isNotNull())                   # Drop null\n",
    "    .filter(trim(col(\"summary\")) != \"\")                   # Drop empty/whitespace\n",
    "    .dropna(how=\"any\")                                     # Drop any other empty rows\n",
    "    .withColumn(\"date\", date_format(\"date\", \"MM-dd-yyyy\")) # Format date\n",
    ")\n",
    "\n",
    "news_silver_df.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"stocks_ai.stocks_news_data.stock_news_silver_layer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51da9ebf-fc58-493a-b24c-1c4ba9290cad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6427618338580443,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Combined_Silver_Layer_Historical+News",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}